# -*- coding: utf-8 -*-
"""Pipeline_detection_YOLOv12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pH1FfUdMpTYBqEduohxXONuowERItkU_

##Upload DataSet :
"""

!nvidia-smi

!pip install roboflow
!pip install ultralytics
!pip install scikit-learn tqdm
!pip install -U pip
!pip install -U ultralytics

"""###Imports:"""

from roboflow import Roboflow
import os
import random
import matplotlib.pyplot as plt
import cv2
from ultralytics import YOLO
import json
import os
import shutil
from collections import defaultdict
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from ultralytics import YOLO

"""###Roboflow DataSets :"""

rf = Roboflow(api_key="KHlvL8wWXLMrMTQSGysw")
project = rf.workspace("projects-gzqta").project("cracks-rtkm0")
version = project.version(5)
Crack = version.download("coco")

rf = Roboflow(api_key="KHlvL8wWXLMrMTQSGysw")
project = rf.workspace("projects-gzqta").project("leak-k2xv1")
version = project.version(3)
Leak = version.download("coco")

rf = Roboflow(api_key="KHlvL8wWXLMrMTQSGysw")
project = rf.workspace("projects-gzqta").project("puddle-tfczq")
version = project.version(2)
Puddle = version.download("coco")

rf = Roboflow(api_key="91TqmIgv8w7tUi53b8Kb")
project = rf.workspace("pipeline-detection").project("pipeline-detection-copy")
version = project.version(1)
pipe1 = version.download("coco")


rf = Roboflow(api_key="PA3kj1H2PlxAKb2sylWl")
project = rf.workspace("mariem-vgz4r").project("pipeline-9nae1")
version = project.version(1)
pipe2 = version.download("coco")

rf = Roboflow(api_key="KHlvL8wWXLMrMTQSGysw")
project = rf.workspace("projects-gzqta").project("pipes-aapxp")
version = project.version(2)
pipe3 = version.download("coco")

#pipes = "/content/drive/MyDrive/Colab Notebooks/DataSet/Pipes"

"""##Data Preparation :"""

import shutil
import os

# Paths to delete
dirs_to_delete = ["merged_dataset", "augmented_dataset","dataset_split"]

for directory in dirs_to_delete:
    if os.path.exists(directory):
        print(f"Deleting {directory}...")
        shutil.rmtree(directory)
    else:
        print(f"{directory} does not exist.")

"""###Merge DataSets :"""

# Paths where datasets are mounted
dataset_dirs = [
    "/content/Cracks-5",   # replace with your dataset folders
    "/content/Leak-3",
    "/content/Puddle-2",
    "/content/pipeline-detection-copy-1",
    "/content/pipeline-1",
    "/content/pipes-2"


]

splits = ["train", "valid", "test"]

# Output merged folder
merged_dir = "merged_dataset"
merged_images_dir = os.path.join(merged_dir, "images")
merged_ann_path = os.path.join(merged_dir, "annotations.json")
os.makedirs(merged_images_dir, exist_ok=True)

# Initialize merged COCO structure
merged_coco = {
    "images": [],
    "annotations": [],
    "categories": [],
}

img_id_offset = 0
ann_id_offset = 0
category_map = {}

print("üöÄ Merging datasets...\n")

for dataset in dataset_dirs:
    for split in splits:
        split_dir = os.path.join(dataset, split)
        ann_file = os.path.join(split_dir, "_annotations.coco.json")

        if not os.path.exists(ann_file):
            print(f"‚ö†Ô∏è Warning: {ann_file} not found.")
            continue

        with open(ann_file, "r") as f:
            coco_data = json.load(f)

        # Categories
        for cat in coco_data["categories"]:
            if cat["name"] not in [c["name"] for c in merged_coco["categories"]]:
                new_id = len(merged_coco["categories"]) + 1
                category_map[cat["id"]] = new_id
                cat_copy = cat.copy()
                cat_copy["id"] = new_id
                merged_coco["categories"].append(cat_copy)
            else:
                existing = next(c for c in merged_coco["categories"] if c["name"] == cat["name"])
                category_map[cat["id"]] = existing["id"]

        # Images
        for img in coco_data["images"]:
            new_img_id = img["id"] + img_id_offset
            img_copy = img.copy()
            img_copy["id"] = new_img_id

            src_img = os.path.join(split_dir, img["file_name"])
            new_filename = f"{new_img_id}_{img['file_name']}"  # üëà unique name
            dst_img = os.path.join(merged_images_dir, new_filename)

            if not os.path.exists(dst_img):
                shutil.copy2(src_img, dst_img)

            img_copy["file_name"] = new_filename  # üëà update annotation
            merged_coco["images"].append(img_copy)
        # Annotations
        for ann in coco_data["annotations"]:
            ann_copy = ann.copy()
            ann_copy["id"] += ann_id_offset
            ann_copy["image_id"] += img_id_offset
            ann_copy["category_id"] = category_map[ann["category_id"]]
            merged_coco["annotations"].append(ann_copy)

        img_id_offset += max([img["id"] for img in coco_data["images"]], default=0) + 1
        ann_id_offset += max([ann["id"] for ann in coco_data["annotations"]], default=0) + 1

# Save merged annotation file
with open(merged_ann_path, "w") as f:
    json.dump(merged_coco, f)

print(f"\n‚úÖ Done! Merged dataset is saved in: '{merged_dir}'")

"""###Class distribution Before Data Augmentation:

"""

from collections import Counter
import json

with open("merged_dataset/annotations.json", "r") as f:
    coco = json.load(f)

id2name = {cat["id"]: cat["name"] for cat in coco["categories"]}
class_counts = Counter()

for ann in coco["annotations"]:
    class_counts[ann["category_id"]] += 1

print("\nüìä Class distribution:")
for cat_id, count in sorted(class_counts.items()):
    print(f"{id2name[cat_id]} (ID {cat_id}): {count} items")

"""### Data Augmentataion :"""

pip install albumentations opencv-python-headless tqdm

def clip_bbox(bbox, width, height):
    x, y, w, h = bbox
    x = max(0, min(x, width - 1))
    y = max(0, min(y, height - 1))
    w = max(0, min(w, width - x))
    h = max(0, min(h, height - y))
    return [x, y, w, h]

import os
import json
import cv2
import shutil
import albumentations as A
from copy import deepcopy
from tqdm import tqdm
import random

# Helper function to clip bbox inside image boundaries
def clip_bbox(bbox, width, height):
    # bbox in COCO format: [x_min, y_min, width, height]
    x_min = max(0, min(bbox[0], width - 1))
    y_min = max(0, min(bbox[1], height - 1))
    w = max(0, min(bbox[2], width - x_min))
    h = max(0, min(bbox[3], height - y_min))
    return [x_min, y_min, w, h]

# Config
merged_dir = "merged_dataset"
merged_ann_path = os.path.join(merged_dir, "annotations.json")
merged_images_dir = os.path.join(merged_dir, "images")

output_dir = "augmented_dataset"
os.makedirs(output_dir, exist_ok=True)
output_images_dir = os.path.join(output_dir, "images")
os.makedirs(output_images_dir, exist_ok=True)

# Target number of samples per class (equal to pipeline count)
TARGET_COUNT = 8575
classes_to_augment = ["crack", "leak", "puddle"]  # classes to augment only

# Load merged COCO annotations
with open(merged_ann_path, "r") as f:
    coco = json.load(f)

# Category mappings
cat_id_to_name = {c['id']: c['name'] for c in coco['categories']}
cat_name_to_id = {v: k for k, v in cat_id_to_name.items()}

# Count current samples per class by annotations
actual_counts = {name: 0 for name in classes_to_augment}
for ann in coco["annotations"]:
    cname = cat_id_to_name[ann["category_id"]]
    if cname in actual_counts:
        actual_counts[cname] += 1

print("üìä Current class counts:", actual_counts)

# Calculate how many samples needed per class
target_counts = {}
for cls in classes_to_augment:
    if actual_counts[cls] < TARGET_COUNT:
        target_counts[cls] = TARGET_COUNT
    else:
        print(f"‚ö†Ô∏è Class '{cls}' has {actual_counts[cls]} samples (no augmentation needed)")

# Albumentations augmentation pipeline for bbox detection
transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.Rotate(limit=15, p=0.5),
    A.Affine(translate_percent=0.05, scale=(0.9, 1.1), rotate=0, p=0.5),
], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))

# Map image_id to annotations
img_id_to_anns = {}
for ann in coco['annotations']:
    img_id_to_anns.setdefault(ann['image_id'], []).append(ann)

# Map image_id to image info
img_id_to_info = {img['id']: img for img in coco['images']}

# Prepare output COCO
augmented_coco = deepcopy(coco)
max_img_id = max(img['id'] for img in coco['images'])
max_ann_id = max(ann['id'] for ann in coco['annotations'])

new_images = []
new_annotations = []

# Track how many augmented annotations added per class
augmented_counts = {cls: 0 for cls in target_counts.keys()}

def augment_and_save(orig_img_info, anns_for_img, augment_times):
    global max_img_id, max_ann_id
    orig_img_path = os.path.join(merged_images_dir, orig_img_info['file_name'])
    image = cv2.imread(orig_img_path)
    if image is None:
        print(f"Cannot read image {orig_img_path}")
        return 0, {}

    height, width = image.shape[:2]
    bboxes = []
    category_ids = []

    # Include only bboxes for classes still needing augmentation
    for ann in anns_for_img:
        cname = cat_id_to_name[ann['category_id']]
        if cname in target_counts and augmented_counts[cname] < (target_counts[cname] - actual_counts[cname]):
            bbox = ann['bbox']
            bbox = clip_bbox(bbox, width, height)
            bboxes.append(bbox)
            category_ids.append(ann['category_id'])

    if not bboxes:
        return 0, {}

    count = 0
    added_counts = {cls: 0 for cls in target_counts.keys()}

    for _ in range(augment_times):
        # Count how many instances per class in this image
        image_class_counts = {}
        for cid in category_ids:
            cname = cat_id_to_name[cid]
            image_class_counts[cname] = image_class_counts.get(cname, 0) + 1

        # Check if augmenting would exceed target for any class
        can_augment = True
        for cname, num_instances in image_class_counts.items():
            if augmented_counts[cname] + num_instances > (target_counts[cname] - actual_counts[cname]):
                can_augment = False
                break

        if not can_augment:
            break  # stop augmenting this image

        augmented = transform(image=image, bboxes=bboxes, category_ids=category_ids)
        aug_img = augmented['image']
        aug_bboxes = augmented['bboxes']
        aug_cat_ids = augmented['category_ids']

        max_img_id += 1
        new_filename = f"aug_{max_img_id}_{orig_img_info['file_name']}"
        new_img_path = os.path.join(output_images_dir, new_filename)
        cv2.imwrite(new_img_path, aug_img)

        new_img_info = deepcopy(orig_img_info)
        new_img_info['id'] = max_img_id
        new_img_info['file_name'] = new_filename
        new_images.append(new_img_info)

        for bbox, cat_id in zip(aug_bboxes, aug_cat_ids):
            max_ann_id += 1
            new_ann = {
                "id": max_ann_id,
                "image_id": max_img_id,
                "category_id": cat_id,
                "bbox": [float(x) for x in bbox],
                "area": float(bbox[2] * bbox[3]),
                "iscrowd": 0,
                "segmentation": [],
            }
            new_annotations.append(new_ann)

            cname = cat_id_to_name[cat_id]
            if cname in added_counts:
                added_counts[cname] += 1

        count += 1

    return count, added_counts

print("Starting augmentation...")

# Main augmentation loop
total_to_augment = {cls: target_counts[cls] - actual_counts[cls] for cls in target_counts}
all_done = False

while not all_done:
    all_done = True
    for cls_name, to_augment in total_to_augment.items():
        if to_augment <= 0:
            continue

        imgs_with_cls = [img_id for img_id in img_id_to_anns if any(
            cat_id_to_name[ann['category_id']] == cls_name for ann in img_id_to_anns[img_id])]

        random.shuffle(imgs_with_cls)

        for img_id in imgs_with_cls:
            if total_to_augment[cls_name] <= 0:
                break
            anns_img = img_id_to_anns[img_id]

            saved, added = augment_and_save(img_id_to_info[img_id], anns_img, augment_times=1)

            for c, count_added in added.items():
                total_to_augment[c] -= count_added
                augmented_counts[c] += count_added

            if total_to_augment[cls_name] > 0:
                all_done = False

print("Augmentation finished.")

# Copy original images to output folder
print("Copying original images...")
for img in tqdm(coco['images']):
    src = os.path.join(merged_images_dir, img['file_name'])
    dst = os.path.join(output_images_dir, img['file_name'])
    if not os.path.exists(dst):
        shutil.copy2(src, dst)

# Update COCO with augmented data
augmented_coco['images'].extend(new_images)
augmented_coco['annotations'].extend(new_annotations)

# Save new annotation JSON
aug_ann_path = os.path.join(output_dir, "annotations_augmented.json")
with open(aug_ann_path, "w") as f:
    json.dump(augmented_coco, f)

print(f"‚úÖ Augmentation complete! New dataset at '{output_dir}'")
print(f"New annotation file: '{aug_ann_path}'")

import json

input_json = "augmented_dataset/annotations_augmented.json"
output_json = "augmented_dataset/annotations_filtered.json"

# Les classes que tu veux garder
wanted_classes = {"crack", "pipeline", "leak", "puddle"}

with open(input_json, "r") as f:
    coco = json.load(f)

# Filtrer les cat√©gories
filtered_categories = [cat for cat in coco["categories"] if cat["name"] in wanted_classes]
wanted_cat_ids = {cat["id"] for cat in filtered_categories}

# Filtrer les annotations pour garder uniquement celles des classes voulues
filtered_annotations = [ann for ann in coco["annotations"] if ann["category_id"] in wanted_cat_ids]

# Optionnel : filtrer les images pour ne garder que celles ayant au moins une annotation
valid_image_ids = {ann["image_id"] for ann in filtered_annotations}
filtered_images = [img for img in coco["images"] if img["id"] in valid_image_ids]

# Mettre √† jour le COCO dict
coco["categories"] = filtered_categories
coco["annotations"] = filtered_annotations
coco["images"] = filtered_images

# Sauvegarder le fichier filtr√©
with open(output_json, "w") as f:
    json.dump(coco, f)

print(f"Fichier filtr√© sauvegard√© dans {output_json}")
print(f"Nombre de classes gard√©es: {len(filtered_categories)}")
print(f"Nombre d'annotations restantes: {len(filtered_annotations)}")
print(f"Nombre d'images restantes: {len(filtered_images)}")

"""###Class distribution **After** Data Augmentation:

"""

with open("augmented_dataset/annotations_filtered.json", "r") as f:
    coco = json.load(f)

id2name = {cat["id"]: cat["name"] for cat in coco["categories"]}
class_counts = Counter()

for ann in coco["annotations"]:
    class_counts[ann["category_id"]] += 1

print("\nüìä Class distribution:")
for cat_id, count in sorted(class_counts.items()):
    print(f"{id2name[cat_id]} (ID {cat_id}): {count} items")

import json

aug_ann_path = "augmented_dataset/annotations_filtered.json"

with open(aug_ann_path, "r") as f:
    coco = json.load(f)

num_images = len(coco["images"])
print(f"Total number of images in the final dataset: {num_images}")

"""## Split Dataset :"""

# Config
augmented_dir ="/content/augmented_dataset"
annotations_file = os.path.join(augmented_dir, "annotations_filtered.json")
images_dir = os.path.join(augmented_dir, "images")

output_dir = "dataset_split"
os.makedirs(output_dir, exist_ok=True)

train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Load COCO JSON
with open(annotations_file, "r") as f:
    coco = json.load(f)

# Map image_id -> list of category_ids
# Map image_id -> list of category_ids
img_to_cats = defaultdict(set)
for ann in coco['annotations']:
    img_to_cats[ann['image_id']].add(ann['category_id'])

images = coco['images']
image_ids = [img['id'] for img in images]

# For stratification, assign each image a single class for simplicity
img_cat_single = []
for img_id in image_ids:
    cats = img_to_cats[img_id]
    if cats:
        img_cat_single.append(min(cats))  # or max, or majority class if you want to implement that
    else:
        img_cat_single.append(-1)  # No class (handle carefully)

# Remove images with no classes if any
img_with_class = [(img_id, cat) for img_id, cat in zip(image_ids, img_cat_single) if cat != -1]
image_ids, img_cat_single = zip(*img_with_class)

# Split train and temp (val+test)
img_train, img_temp, cat_train, cat_temp = train_test_split(
    image_ids, img_cat_single, stratify=img_cat_single, test_size=(1 - train_ratio), random_state=42)

# Split val and test
val_size = val_ratio / (val_ratio + test_ratio)
img_val, img_test, _, _ = train_test_split(
    img_temp, cat_temp, stratify=cat_temp, test_size=(1 - val_size), random_state=42)

print(f"Train images: {len(img_train)}")
print(f"Validation images: {len(img_val)}")
print(f"Test images: {len(img_test)}")

# Helper: get annotations for given images
def filter_coco(images_subset):
    images_filtered = [img for img in coco['images'] if img['id'] in images_subset]
    image_ids_set = set(images_subset)
    annotations_filtered = [ann for ann in coco['annotations'] if ann['image_id'] in image_ids_set]

    return {
        "images": images_filtered,
        "annotations": annotations_filtered,
        "categories": coco['categories'],
    }

# Save splits COCO JSON and copy images
for split_name, img_ids in zip(["train", "val", "test"], [img_train, img_val, img_test]):
    print(f"Processing split: {split_name}")
    split_dir = os.path.join(output_dir, split_name)
    os.makedirs(os.path.join(split_dir, "images"), exist_ok=True)

    split_coco = filter_coco(img_ids)

    # Save JSON
    with open(os.path.join(split_dir, f"annotations_{split_name}.json"), "w") as f:
        json.dump(split_coco, f)

    # Copy images
    for img in tqdm(split_coco['images']):
        src_path = os.path.join(images_dir, img['file_name'])
        dst_path = os.path.join(split_dir, "images", img['file_name'])
        if not os.path.exists(dst_path):
            shutil.copy2(src_path, dst_path)

print("Dataset split complete!")

import shutil

# Path to your dataset in Colab
dataset_path = "/content/dataset_split"  # folder or file

# Destination folder in Drive
drive_path = "/content/drive/MyDrive/Colab Notebooks/DataSet/dataset_split_yolo"

# Copy the folder (set dirs_exist_ok=True to overwrite if exists)
shutil.copytree(dataset_path, drive_path, dirs_exist_ok=True)

print(f"‚úÖ Dataset uploaded to: {drive_path}")

"""### Clasees Distribution after splitting :"""

import json
from collections import Counter, defaultdict

# Paths to your split annotation files (adjust as needed)
splits = {
    "train": "dataset_split/train/annotations_train.json",
    "val": "dataset_split/val/annotations_val.json",
    "test": "dataset_split/test/annotations_test.json",
}

for split_name, ann_path in splits.items():
    with open(ann_path, "r") as f:
        coco = json.load(f)

    # Map category id to name
    cat_id_to_name = {cat['id']: cat['name'] for cat in coco['categories']}

    # Count annotations per category id
    class_counts = Counter()
    for ann in coco["annotations"]:
        class_counts[ann["category_id"]] += 1

    print(f"\nüìä Class distribution in {split_name}:")
    for cat_id, count in class_counts.items():
        print(f"  {cat_id_to_name[cat_id]} (ID {cat_id}): {count} items")

import os

def print_structure(root_dir):
    print(f"{os.path.basename(root_dir)}/")
    for main_folder in sorted(os.listdir(root_dir)):
        main_path = os.path.join(root_dir, main_folder)
        if os.path.isdir(main_path):
            print(f"  {main_folder}/")
            for subfolder in sorted(os.listdir(main_path)):
                subfolder_path = os.path.join(main_path, subfolder)
                if os.path.isdir(subfolder_path):
                    print(f"    {subfolder}/")

# Replace this with your actual dataset folder path
dataset_root = "/content/dataset_split"

print_structure(dataset_root)

"""#### YOLOV12 Data Structure :"""

import os

# Base path of the dataset
base_path = "dataset_split"

# Subsets to create labels/ folders for
splits = ["train", "val", "test"]

# Create labels directories if they don't exist
for split in splits:
    labels_path = os.path.join(base_path, split, "labels")
    os.makedirs(labels_path, exist_ok=True)

labels_dirs = [os.path.join(base_path, split, "labels") for split in splits]
labels_dirs

"""### Script de conversion COCO ‚Üí YOLOv12 :"""

import json
import os
from tqdm import tqdm

# === Chemins ===
coco_json_path = "augmented_dataset/annotations_filtered.json"  # Fichier COCO d'origine
images_base_dir = "dataset_split"  # R√©pertoire o√π train/val/test sont stock√©s

# === Charger COCO JSON ===
with open(coco_json_path, "r") as f:
    coco = json.load(f)

# === Pr√©parer mappage image_id -> (file_name, width, height)
image_info = {img["id"]: img for img in coco["images"]}

# === Mappage cat√©gorie_id -> index YOLO (commence √† 0)
categories = sorted(coco["categories"], key=lambda x: x["id"])
cat_id_to_yolo_id = {cat["id"]: i for i, cat in enumerate(categories)}
print("\nüìã Mapping COCO ID ‚Üí YOLO ID :")
for i, cat in enumerate(categories):
    print(f"YOLO ID {i}: {cat['name']} (COCO ID {cat['id']})")


# === Regrouper annotations par image_id
annotations_by_image = {}
for ann in coco["annotations"]:
    image_id = ann["image_id"]
    annotations_by_image.setdefault(image_id, []).append(ann)

# === Fonction de conversion COCO -> YOLO format ===
def coco_to_yolo_bbox(bbox, img_width, img_height):
    x, y, w, h = bbox
    x_center = (x + w / 2) / img_width
    y_center = (y + h / 2) / img_height
    w /= img_width
    h /= img_height
    return [x_center, y_center, w, h]

# === Appliquer conversion √† chaque split ===
splits = ["train", "val", "test"]
for split in splits:
    print(f"\nüìÇ Traitement split: {split}")
    image_dir = os.path.join(images_base_dir, split, "images")
    label_dir = os.path.join(images_base_dir, split, "labels")
    os.makedirs(label_dir, exist_ok=True)

    images_in_split = os.listdir(image_dir)
    img_filenames = set(images_in_split)

    count = 0
    for img_id, img_data in tqdm(image_info.items()):
        file_name = img_data["file_name"]
        if file_name not in img_filenames:
            continue  # ne fait pas partie de ce split

        annots = annotations_by_image.get(img_id, [])
        yolo_lines = []
        for ann in annots:
            category_id = ann["category_id"]
            yolo_id = cat_id_to_yolo_id[category_id]
            bbox = coco_to_yolo_bbox(ann["bbox"], img_data["width"], img_data["height"])
            line = f"{yolo_id} {' '.join(f'{v:.6f}' for v in bbox)}"
            yolo_lines.append(line)

        # Sauvegarder fichier .txt
        txt_filename = os.path.splitext(file_name)[0] + ".txt"
        txt_path = os.path.join(label_dir, txt_filename)
        with open(txt_path, "w") as f:
            f.write("\n".join(yolo_lines))
        count += 1

    print(f"‚úÖ {count} fichiers d'annotation YOLO cr√©√©s dans {label_dir}")

"""### data.yaml File Creation :"""

import yaml

# Define absolute paths (assuming you're in /content/)
data_yaml = {
    'train': '/content/dataset_split/train/images',
    'val': '/content/dataset_split/val/images',
    'test': '/content/dataset_split/test/images',
    'nc': 4,
    'names': ['crack', 'pipeline', 'leak', 'puddle']
}

# Save the data.yaml file
with open('/content/dataset_split/data.yaml', 'w') as f:
    yaml.dump(data_yaml, f, default_flow_style=False)

print("‚úÖ data.yaml file created at /content/dataset_split/data.yaml")

"""## Modeling YOLOV12 :

#### Yolov12 X :
"""

from ultralytics import YOLO
model = YOLO("yolo12n.pt")

!yolo task=detect mode=train model=yolo12n.pt data=/content/dataset_split/data.yaml epochs=40 imgsz=640

from google.colab import files

files.download("runs/detect/train/weights/best.pt")

import shutil


# Copy model to Drive
shutil.copy("runs/detect/train/weights/best.pt", "/content/drive/MyDrive/Colab Notebooks/Models")
print("‚úÖ Model saved to Google Drive")

!yolo task=detect mode=val model="/content/runs/detect/train/weights/best.pt" data=/content/dataset_split/data.yaml

"""####test vid1 :"""

from google.colab import files
files.upload()

from google.colab import files
uploaded = files.upload()

!yolo task=detect \
    mode=predict \
    model="/content/yolov12s.pt" \
    source="/content/videos_tes/" \
    conf=0.25 \
    imgsz=640 \
    save=True \
    save_txt=True

import subprocess
import glob

avi_files = glob.glob("/content/runs/detect/predict/*.avi")

for f in avi_files:
    mp4_file = f.replace(".avi", ".mp4")
    subprocess.run(["ffmpeg", "-i", f, "-vcodec", "libx264", "-acodec", "aac", mp4_file])

!ffmpeg -i /content/runs/detect/predict/mission_video_2025-07-23_16-57-20.avi -vcodec libx264 -acodec aac /content/output.mp4

from IPython.display import Video
Video("/content/runs/detect/predict/mission_video_2025-07-23_16-57-20.avi", embed=True)

!yolo task=detect \
    mode=predict \
    model="/content/yolov12_results/content/runs/detect/train3/weights/best.pt" \
    source="/content/WhatsApp Vid√©o 2025-07-18 √† 16.01.54_20ed54db.mp4" \
    conf=0.25 \
    imgsz=640 \
    save=True \
    save_txt=True

!ffmpeg -i /content/runs/detect/predict/WhatsApp Vid√©o 2025-07-18 √† 16.04.22_f1bd593e.avi -vcodec libx264 -acodec aac /content/output.mp4

"""### YOLOv12 S 1st configuration :

"""

!yolo task=detect mode=train model=yolo12s.pt \
  data=/content/dataset_split/data.yaml \
  epochs=50 imgsz=512 batch=2 \
  cos_lr=True warmup_epochs=5.0 dropout=0.2 \
  project="detection" name="run1"

from google.colab import files
files.download('/content/detection/run1/weights/best.pt')

"""### YOLOv12 S 2nd configuration :

"""

for start_epoch in range(0, 100, 10):
    !yolo task=detect mode=train model=/content/drive/MyDrive/last.pt \
      data=/content/dataset_split/data.yaml \
      epochs={start_epoch + 10} imgsz=512 batch=2 \
      cos_lr=True warmup_epochs=5.0 dropout=0.2 \
      project="detection" name="run1"

"""### YOLOv12 S 3rd configuration :

"""

!yolo task=detect mode=train model=yolov12s.pt \
  data=/content/dataset_split/data.yaml \
  epochs=100 imgsz=640 batch=8 \
  lr0=0.001 lrf=0.01 momentum=0.937 weight_decay=0.0005 \
  cos_lr=True warmup_epochs=3.0 warmup_bias_lr=0.1 \
  dropout=0.1 amp=True \
  hsv_h=0.015 hsv_s=0.7 hsv_v=0.4 degrees=0.0 translate=0.1 scale=0.5 shear=0.0 flipud=0.0 fliplr=0.5 \
  mosaic=1.0 mixup=0.1 copy_paste=0.1 \
  project="detection" name="run3"

"""##video tests"""

!yolo task=detect \
    mode=predict \
    model="/content/yolov12_results/content/runs/detect/train3/weights/best.pt" \
    source="/content/WhatsApp Vid√©o 2025-07-18 √† 16.01.54_20ed54db.mp4" \
    conf=0.25 \
    imgsz=640 \
    save=True \
    save_txt=True